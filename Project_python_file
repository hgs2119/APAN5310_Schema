#Load Librarys
import pandas as pd
import numpy as np
import psycopg2
import os

#Load files
df_main = pd.read_csv(".csv") #insert document here
df_product = pd.read_csv("product_table.csv") 
df_country = pd.read_csv("product_table.csv") 


#connect to database
conn = psycopg2.connect(
    host="localhost", 
    database="postgres", #please change database 
    user="postgres", #please change user name
    password="123") #please change password

#create a cursor
conn.autocommit = True
cur = conn.cursor()

#if table exist, drop table
query =  "DROP TABLE IF EXISTS Investigations;"
query += "DROP TABLE IF EXISTS Publications;"
query += "DROP TABLE IF EXISTS Determinations;"
query += "DROP TABLE IF EXISTS Country;"
query += "DROP TABLE IF EXISTS Products;"
query += "DROP TABLE IF EXISTS Date_Dim;"
query += "DROP TABLE IF EXISTS Commodities;"
query += "DROP TABLE IF EXISTS Case_Groups;"
query += "DROP TABLE IF EXISTS Staff_Assigned;"
query += "DROP TABLE IF EXISTS Commissioners;"
query += "DROP TABLE IF EXISTS Law_Firms;"
query += "DROP TABLE IF EXISTS Petitioning_Firms;"
query += "DROP TABLE IF EXISTS date_sequence;"

cur.execute(query)

#create Country table
query = "CREATE TABLE Country ( \
    Country_Code char(3) NOT NULL,\
    Country_Name varchar(100),\
    Region varchar(100),\
    Trade_Relationship varchar(50),\
	PRIMARY KEY (Country_Code)\
    );"
cur.execute(query)

#make dataframe for Country
df_Country = df[['Country', 'Trade_Relationship']].copy()
df_Country.drop_duplicates(inplace=True)
df_Country = df_Country.reset_index(drop=True)
df_Country.reset_index(inplace=True)

#insert data into Country table
Country_dict = {}
for index, row in df_Country.iterrows():
    Country_dict[row['Country']] = row['index']
    query = f"insert into Country (Country_Code, Country_Name, Region, Trade_Relationship) values ({row['index']}, '{row['Country']}', {row['Trade_Relationship']});"
    cur.execute(query)

#create Products table
query = "CREATE TABLE Products (
    Product_ID char(3) NOT NULL,\
    Product_Name varchar(100),\
    Product_Type varchar(100),\
	PRIMARY KEY (Country_Code)\
        );"
        
cur.execute(query)

#make dataframe for Products
df_Products = df[['Products']].copy()
df_Products.drop_duplicates(inplace=True)
df_Products = df_Products.reset_index(drop=True)
df_Products.reset_index(inplace=True)

#insert data into Products table
Products_dict = {}
for index, row in df_Products.iterrows():
    Products_dict[row['Products']] = row['index']
    query = f"insert into Manufacturer (Product_ID, Product_Name,Product_Type) values ({row['index']}, '{row['Products']}');"
    cur.execute(query)
    
   
#create date_sequence table
query = "CREATE TABLE date_sequence (date date NOT NULL)
)";
cur.execute(query)

#Insert Records into date_sequence table
query = "INSERT INTO
  date_sequence(date)
SELECT
  '1960-01-01'::DATE + SEQUENCE.number AS date
FROM
  GENERATE_SERIES(0, 27000) AS SEQUENCE (number)
  )";
cur.execute(query)

#create date_dim table
query = "CREATE TABLE date_dim (
  date_value DATE NOT NULL, \
  day_suffix TEXT NOT NULL, \
  day_name TEXT NOT NULL, \
  day_of_week INT NOT NULL, \
  day_of_month INT NOT NULL, \
  day_of_year INT NOT NULL, \
  month INT NOT NULL, \
  month_name TEXT NOT NULL, \
  month_name_abbreviated TEXT NOT NULL, \
  year_value INT NOT NULL, \
  quarter INT NOT NULL, \
  first_day_of_week DATE NOT NULL, \
  last_day_of_week DATE NOT NULL \
);"
cur.execute(query)

#Insert Records into date_sequence table

query = "INSERT INTO date_dim
SELECT   \
date as date,   \
TO_CHAR(date, 'fmDDth') AS day_suffix,  \
TO_CHAR(date, 'TMDay') AS day_name, \
EXTRACT(ISODOW FROM date) AS day_of_week, \ 
EXTRACT(DAY FROM date) AS day_of_month,  \ 
EXTRACT(DOY FROM date) AS day_of_year,   \
EXTRACT(MONTH FROM date) AS month,   \
TO_CHAR(date, 'TMMonth') AS month_name,   \
TO_CHAR(date, 'Mon') AS month_name_abbreviated,   \
EXTRACT(YEAR FROM date) AS year_value,   \
EXTRACT(quarter FROM date) AS quarter, \
date + (1 - EXTRACT(ISODOW FROM date))::INT AS first_day_of_week,   date + (7 - EXTRACT(ISODOW FROM date))::INT AS last_day_of_week from date_sequence \
ORDER BY date ASC \
);"

cur.execute(query)


#create Commodities table
query = "CREATE TABLE Commodities (
    HS_codes char(3) NOT NULL, \
    HS_description varchar(500), \
	PRIMARY KEY (HS_Codes) \
         );"
cur.execute(query)

#make dataframe for Commodities
df_Commodities = df[['HS_codes', 'HS_description']].copy()
df_Commodities = df_Commodities[df_Commodities['HS_codes'].notna()]
df_Commodities.drop_duplicates(inplace=True)

#insert data into Commodities table
for index, row in df_Commodities.iterrows():
    for comd in softlst:
        query = f"insert into Software (HS_codes, HS_description) values ('{row['HS_codes']}', '{comd}');"
        cur.execute(query)

#create Commissioners table
query = "CREATE TABLE Commissioners   (
    ID char(10) NOT NULL, \
    Commissioner_Name varchar(150), \
    Title varchar(150), \
	PRIMARY KEY (ID) \
    );"
    
cur.execute(query)

#make dataframe for Commissioners
df_Commissioners = df[['ID', 'Title']].copy()
df_Commissioners.drop_duplicates(inplace=True)
df_Commissioners = df_Commissioners.reset_index(drop=True)
df_Commissioners.reset_index(inplace=True)

#insert data into Country table
Commissioners_dict = {}
for index, row in df_Commissioners.iterrows():
    Commissioners_dict[row['Commissioners']] = row['index']
    query = f"insert into Country (ID, Commissioner_Name, Title) values ({row['index']}, '{row['Commissioners']}', {row['Title']});"
    cur.execute(query)
	


cur.close()
